{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX2BRIJ8R4BG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8la4a3iR-Ko"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/4995_Competition/4995_kaggle_competition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siMf8Xgpi_p3"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMZAUFHrsG9L"
   },
   "source": [
    "### Load price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvhgeI7eSCPw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "prices = pd.read_csv('train.csv')\n",
    "dates = prices['Unnamed: 0']\n",
    "prices = prices.iloc[:,1:].set_index(dates)\n",
    "prices.index.name = 'date'\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3YmbpmIUWjy"
   },
   "source": [
    "###Calculate Returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKPo6v9LUV9v"
   },
   "outputs": [],
   "source": [
    "rets = (prices.shift(1)-prices)\n",
    "rets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DG5pKXkNh5L1"
   },
   "source": [
    "### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxIinBDFSJ-b"
   },
   "outputs": [],
   "source": [
    "# Fill prices\n",
    "prices = prices.fillna(method='bfill', axis='rows', inplace=False)\n",
    "prices = prices.fillna(0, axis='rows', inplace=False)\n",
    "\n",
    "# Fill returns\n",
    "rets = rets.fillna(0, axis='rows', inplace=False)\n",
    "rets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRNBUGEGw6yb"
   },
   "outputs": [],
   "source": [
    "# Confirm all non null values\n",
    "for i in range(rets.shape[1]):\n",
    "    assert not np.isnan(rets.iloc[:, i]).any() or not np.isnan(prices.iloc[:, i]).any()\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWcgVJbYcY52"
   },
   "outputs": [],
   "source": [
    "rets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C46I3Gc1ktgG"
   },
   "source": [
    "### Manually create dataset for recurrent network\n",
    "- default lookback period: 50 days\n",
    "- sample dimension: lookback period x 505 stocks\n",
    "\n",
    "#### Create X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHwshfQudmzw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "N_STOCKS = 505\n",
    "WINDOW = 50\n",
    "BIAS = 0.01\n",
    "\n",
    "def create_data(prices, window, pred_length=152, normalize=True):\n",
    "    \"\"\"\n",
    "    creates data samples of window length x N_STOCKS using the\n",
    "    previous window length days\n",
    "    return: [0-49, 1-50, 2-52, .., 841-890]\n",
    "    \"\"\"\n",
    "    X_fcc = []\n",
    "    X_lstm = []\n",
    "\n",
    "    # Scale values between 0 and 1\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    for i in range(prices.shape[0]-window):\n",
    "        labels = prices.iloc[i:i+window,:].to_numpy()\n",
    "        if normalize:\n",
    "            labels = scaler.fit_transform(labels)\n",
    "        \n",
    "        X_lstm.append(labels)\n",
    "\n",
    "        # Flatten values for FCC\n",
    "        X_fcc.append(labels.flatten())\n",
    "        \n",
    "    return np.array(X_fcc), np.array(X_lstm)\n",
    "\n",
    "X_fcc, X_lstm = create_data(prices, WINDOW, normalize=True)\n",
    "y = create_targets(rets, WINDOW, pred_length=152)\n",
    "\n",
    "X_fcc.shape, X_lstm.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gG9B3e0k9E5P"
   },
   "source": [
    "### Create Y targets (method 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BO3tz4YG9FTi"
   },
   "outputs": [],
   "source": [
    "def get_weights(sharpe_vals, i):\n",
    "    # calc norm values\n",
    "    pos_norm = 0\n",
    "    neg_norm = 0\n",
    "    for val in sharpe_vals:\n",
    "        if val > 0:\n",
    "            pos_norm += val\n",
    "        else:\n",
    "            neg_norm += val\n",
    "\n",
    "    # normalize values\n",
    "    pos_sum = 0\n",
    "    neg_sum = 0\n",
    "    for i in range(len(sharpe_vals)):\n",
    "        if sharpe_vals[i] > 0:\n",
    "            sharpe_vals[i] = sharpe_vals[i]/pos_norm\n",
    "            pos_sum += sharpe_vals[i]\n",
    "        else:\n",
    "            sharpe_vals[i] = sharpe_vals[i]/(-neg_norm)\n",
    "            neg_sum += sharpe_vals[i]\n",
    "\n",
    "    # scale to 1 given bias\n",
    "    scale_factor = 1-BIAS\n",
    "    weights = sharpe_vals*scale_factor\n",
    "\n",
    "    # error checking\n",
    "    assert weights.idxmax() == sharpe_vals.idxmax()\n",
    "    assert weights.idxmin() == sharpe_vals.idxmin()\n",
    "    if np.isnan(weights).any():\n",
    "        print(sharpe_vals, i)\n",
    "        raise Exception\n",
    "\n",
    "    return weights\n",
    "\n",
    "def validate_values(targets):\n",
    "    for i in range(len(targets)):\n",
    "        if np.isinf(targets[i]) or np.isnan(targets[i]) or np.isneginf(targets[i]):\n",
    "            targets[i] = 0\n",
    "    assert targets.shape == (N_STOCKS,)\n",
    "    return targets\n",
    "\n",
    "def create_targets(rets, window, pred_length=152):\n",
    "    \"\"\"\n",
    "    returns target weights: [50, 51, ..., 739]\n",
    "    \"\"\"\n",
    "    targets = []\n",
    "\n",
    "    for i in range(window, rets.shape[0]-pred_length):\n",
    "        # expected returns/std\n",
    "        ev = rets.iloc[i:i+pred_length, :-1].mean()\n",
    "        std = rets.iloc[i:i+pred_length, :-1].std()\n",
    "\n",
    "        # sharpe vals\n",
    "        sharpe_vals = validate_values(ev / std)\n",
    "\n",
    "        # get weights\n",
    "        stock_weights = get_weights(sharpe_vals, i)\n",
    "\n",
    "        # add to targets\n",
    "        targets.append(np.hstack([stock_weights, [BIAS]]))  \n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxvXPLaS9T0O"
   },
   "source": [
    "### Create Y targets (Method 2): Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0et4AQYs9Bv-"
   },
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "def calc_targets(prices):\n",
    "    targets = []\n",
    "    for i in range(152, prices.shape[0]):\n",
    "        # calc expected returns\n",
    "        avg_returns = expected_returns.mean_historical_return(prices.iloc[i-152:i,:])\n",
    "\n",
    "        # calc diagonal covariance matrix\n",
    "        cov_mat = risk_models.sample_cov(prices.iloc[:150,:])\n",
    "        diag_mat = cov_mat*np.identity(N_STOCKS)\n",
    "\n",
    "        # find optimal weights\n",
    "        ef = EfficientFrontier(avg_returns, cov_mat)\n",
    "        weights = ef.min_volatility()\n",
    "\n",
    "        # truncate and round values\n",
    "        cleaned_weights = ef.clean_weights()\n",
    "        targets.append(cleaned_weights)\n",
    "    \n",
    "    return targets\n",
    "\n",
    "y_ef = calc_targets(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9e_GyDYXhlvq"
   },
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRNtLw7FfPEo"
   },
   "outputs": [],
   "source": [
    "def split_train_data(X):\n",
    "    \"\"\"\n",
    "    return: X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    return X[:689,:], X[689:,:]\n",
    "\n",
    "X_train_fcc, X_test_fcc = split_train_data(X_fcc)\n",
    "X_train_lstm, X_test_lstm = split_train_data(X_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WulnDGpqe7ay"
   },
   "source": [
    "# FCC Neural Net\n",
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Aadg4LKe62p"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, ELU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_fcc_model(lr=0.000001, loss='mse'):\n",
    "    optim = Adam(lr=lr)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=25300))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(256))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(256))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(N_STOCKS+1, activation='tanh'))\n",
    "    model.compile(optimizer=optim, loss=loss)\n",
    "    return model\n",
    "\n",
    "fcc_model = create_fcc_model()\n",
    "fcc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZs7R_e4rUEl"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BInwjCKLf97s"
   },
   "outputs": [],
   "source": [
    "fcc_model.fit(X_train_fcc, y, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt35WjpzsYeC"
   },
   "source": [
    "# LSTM\n",
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTwB-xKKsXug"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model(lr=0.01, dropout=0.2, loss='mae'):\n",
    "    optim = Adam(lr=lr)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(CuDNNLSTM(units=128, return_sequences=True,))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(CuDNNLSTM(units=128))\n",
    "    model.add(Dense(units=N_STOCKS))\n",
    "    model.compile(optimizer=optim, loss=loss)\n",
    "    return model\n",
    "\n",
    "lstm = create_model()\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kfRY_Om8D5J"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9HF53W8nuyr"
   },
   "outputs": [],
   "source": [
    "lstm.fit(X_train_lstm, y, epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFZcePZrpVCE"
   },
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-PjMCNrpW_G"
   },
   "outputs": [],
   "source": [
    "DAYS_N = 152\n",
    "\n",
    "def create_submission(model, Xte, prices, file_name):\n",
    "    # Predictions\n",
    "    preds = model.predict(Xte).flatten()\n",
    "    assert len(preds) == DAYS_N*(N_STOCKS+1)\n",
    "\n",
    "    # Data Id labels\n",
    "    dataid = []\n",
    "    stock_names = prices.columns\n",
    "    for i in range(DAYS_N):\n",
    "        for stock in stock_names:\n",
    "            dataid.append(str(i)+'_'+str(stock))\n",
    "    \n",
    "    assert len(dataid) == DAYS_N*(N_STOCKS+1)\n",
    "    dataid = np.array(dataid)\n",
    "\n",
    "    # Combine for submission\n",
    "    df = pd.DataFrame({'Id':dataid, 'Predicted': preds})\n",
    "    df.to_csv(file_name+'.csv', index=False)\n",
    "\n",
    "    print(\"Submission: {}.csv Created\".format(file_name))\n",
    "\n",
    "create_submission(fcc_model, X_test, prices, 'sub_fcc')\n",
    "create_submission(lstm_model, X_test, prices, 'sub_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9lu0Nln9s1H"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uJ2FWWF9s35"
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as sco\n",
    "\n",
    "def portfolio_annualised_performance(weights, mean_returns, cov_matrix):\n",
    "    returns = np.sum(mean_returns*weights) * 252\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "    return std, returns\n",
    "\n",
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_var\n",
    "\n",
    "def pos_constraint(x):\n",
    "    # positive values\n",
    "    pos_vals = [val for val in x if val >= 0]\n",
    "\n",
    "    # sum(pos_vals) = 1\n",
    "    return sum(pos_vals) - 1\n",
    "\n",
    "def neg_constraint(x):\n",
    "    # negative values\n",
    "    neg_vals = [val for val in x if val < 0]\n",
    "    \n",
    "    # sum(neg_vals) = -1\n",
    "    return sum(neg_vals) + 1\n",
    "\n",
    "def max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "\n",
    "    # constraints\n",
    "    con1 = {'type': 'eq', 'fun': pos_constraint}\n",
    "    con2 = {'type': 'eq', 'fun': neg_constraint}\n",
    "    constraints = [con1, con2] \n",
    "\n",
    "    # bounds\n",
    "    bound = (-1.0, 1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "    # minimize objective neg_sharpe_ratio\n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H248bH-F9s5x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
