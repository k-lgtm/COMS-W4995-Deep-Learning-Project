{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX2BRIJ8R4BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8la4a3iR-Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/4995_Competition/4995_kaggle_competition\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siMf8Xgpi_p3",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMZAUFHrsG9L",
        "colab_type": "text"
      },
      "source": [
        "### Load price data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhgeI7eSCPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "\n",
        "prices = pd.read_csv('train.csv')\n",
        "dates = prices['Unnamed: 0']\n",
        "prices = prices.iloc[:,1:].set_index(dates)\n",
        "prices.index.name = 'date'\n",
        "prices.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YmbpmIUWjy",
        "colab_type": "text"
      },
      "source": [
        "###Calculate Returns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKPo6v9LUV9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rets = (prices.shift(1)-prices)\n",
        "rets.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG5pKXkNh5L1",
        "colab_type": "text"
      },
      "source": [
        "### Fill NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxIinBDFSJ-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill prices\n",
        "prices = prices.fillna(method='bfill', axis='rows', inplace=False)\n",
        "prices = prices.fillna(0, axis='rows', inplace=False)\n",
        "\n",
        "# Fill returns\n",
        "rets = rets.fillna(0, axis='rows', inplace=False)\n",
        "rets.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRNBUGEGw6yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirm all non null values\n",
        "for i in range(rets.shape[1]):\n",
        "    assert not np.isnan(rets.iloc[:, i]).any() or not np.isnan(prices.iloc[:, i]).any()\n",
        "print(\"Success\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcgVJbYcY52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rets.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C46I3Gc1ktgG",
        "colab_type": "text"
      },
      "source": [
        "### Manually create dataset for recurrent network\n",
        "- default lookback period: 50 days\n",
        "- sample dimension: lookback period x 505 stocks\n",
        "\n",
        "#### Create X values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHwshfQudmzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "N_STOCKS = 505\n",
        "WINDOW = 50\n",
        "BIAS = 0.01\n",
        "\n",
        "def create_data(prices, window, pred_length=152, normalize=True):\n",
        "    \"\"\"\n",
        "    creates data samples of window length x N_STOCKS using the\n",
        "    previous window length days\n",
        "    return: [0-49, 1-50, 2-52, .., 841-890]\n",
        "    \"\"\"\n",
        "    X_fcc = []\n",
        "    X_lstm = []\n",
        "\n",
        "    # Scale values between 0 and 1\n",
        "    if normalize:\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "    for i in range(prices.shape[0]-window):\n",
        "        labels = prices.iloc[i:i+window,:].to_numpy()\n",
        "        if normalize:\n",
        "            labels = scaler.fit_transform(labels)\n",
        "        \n",
        "        X_lstm.append(labels)\n",
        "\n",
        "        # Flatten values for FCC\n",
        "        X_fcc.append(labels.flatten())\n",
        "        \n",
        "    return np.array(X_fcc), np.array(X_lstm)\n",
        "\n",
        "X_fcc, X_lstm = create_data(prices, WINDOW, normalize=True)\n",
        "y = create_targets(rets, WINDOW, pred_length=152)\n",
        "\n",
        "X_fcc.shape, X_lstm.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG9B3e0k9E5P",
        "colab_type": "text"
      },
      "source": [
        "### Create Y targets (method 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO3tz4YG9FTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(sharpe_vals, i):\n",
        "    # calc norm values\n",
        "    pos_norm = 0\n",
        "    neg_norm = 0\n",
        "    for val in sharpe_vals:\n",
        "        if val > 0:\n",
        "            pos_norm += val\n",
        "        else:\n",
        "            neg_norm += val\n",
        "\n",
        "    # normalize values\n",
        "    pos_sum = 0\n",
        "    neg_sum = 0\n",
        "    for i in range(len(sharpe_vals)):\n",
        "        if sharpe_vals[i] > 0:\n",
        "            sharpe_vals[i] = sharpe_vals[i]/pos_norm\n",
        "            pos_sum += sharpe_vals[i]\n",
        "        else:\n",
        "            sharpe_vals[i] = sharpe_vals[i]/(-neg_norm)\n",
        "            neg_sum += sharpe_vals[i]\n",
        "\n",
        "    # scale to 1 given bias\n",
        "    scale_factor = 1-BIAS\n",
        "    weights = sharpe_vals*scale_factor\n",
        "\n",
        "    # error checking\n",
        "    assert weights.idxmax() == sharpe_vals.idxmax()\n",
        "    assert weights.idxmin() == sharpe_vals.idxmin()\n",
        "    if np.isnan(weights).any():\n",
        "        print(sharpe_vals, i)\n",
        "        raise Exception\n",
        "\n",
        "    return weights\n",
        "\n",
        "def validate_values(targets):\n",
        "    for i in range(len(targets)):\n",
        "        if np.isinf(targets[i]) or np.isnan(targets[i]) or np.isneginf(targets[i]):\n",
        "            targets[i] = 0\n",
        "    assert targets.shape == (N_STOCKS,)\n",
        "    return targets\n",
        "\n",
        "def create_targets(rets, window, pred_length=152):\n",
        "    \"\"\"\n",
        "    returns target weights: [50, 51, ..., 739]\n",
        "    \"\"\"\n",
        "    targets = []\n",
        "\n",
        "    for i in range(window, rets.shape[0]-pred_length):\n",
        "        # expected returns/std\n",
        "        ev = rets.iloc[i:i+pred_length, :-1].mean()\n",
        "        std = rets.iloc[i:i+pred_length, :-1].std()\n",
        "\n",
        "        # sharpe vals\n",
        "        sharpe_vals = validate_values(ev / std)\n",
        "\n",
        "        # get weights\n",
        "        stock_weights = get_weights(sharpe_vals, i)\n",
        "\n",
        "        # add to targets\n",
        "        targets.append(np.hstack([stock_weights, [BIAS]]))  \n",
        "    return np.array(targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxvXPLaS9T0O",
        "colab_type": "text"
      },
      "source": [
        "### Create Y targets (Method 2): Efficient Frontier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0et4AQYs9Bv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "\n",
        "def calc_targets(prices):\n",
        "    targets = []\n",
        "    for i in range(152, prices.shape[0]):\n",
        "        # calc expected returns\n",
        "        avg_returns = expected_returns.mean_historical_return(prices.iloc[i-152:i,:])\n",
        "\n",
        "        # calc diagonal covariance matrix\n",
        "        cov_mat = risk_models.sample_cov(prices.iloc[:150,:])\n",
        "        diag_mat = cov_mat*np.identity(N_STOCKS)\n",
        "\n",
        "        # find optimal weights\n",
        "        ef = EfficientFrontier(avg_returns, cov_mat)\n",
        "        weights = ef.min_volatility()\n",
        "\n",
        "        # truncate and round values\n",
        "        cleaned_weights = ef.clean_weights()\n",
        "        targets.append(cleaned_weights)\n",
        "    \n",
        "    return targets\n",
        "\n",
        "y_ef = calc_targets(prices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_GyDYXhlvq",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRNtLw7FfPEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_data(X):\n",
        "    \"\"\"\n",
        "    return: X_train, y_train, X_test, y_test\n",
        "    \"\"\"\n",
        "    return X[:689,:], X[689:,:]\n",
        "\n",
        "X_train_fcc, X_test_fcc = split_train_data(X_fcc)\n",
        "X_train_lstm, X_test_lstm = split_train_data(X_lstm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WulnDGpqe7ay",
        "colab_type": "text"
      },
      "source": [
        "# FCC Neural Net\n",
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aadg4LKe62p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, ELU\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def create_fcc_model(lr=0.000001, loss='mse'):\n",
        "    optim = Adam(lr=lr)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=25300))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(128))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(256))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(256))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(128))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(N_STOCKS+1, activation='tanh'))\n",
        "    model.compile(optimizer=optim, loss=loss)\n",
        "    return model\n",
        "\n",
        "fcc_model = create_fcc_model()\n",
        "fcc_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZs7R_e4rUEl",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BInwjCKLf97s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fcc_model.fit(X_train_fcc, y, epochs=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt35WjpzsYeC",
        "colab_type": "text"
      },
      "source": [
        "# LSTM\n",
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTwB-xKKsXug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, CuDNNLSTM, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def create_model(lr=0.01, dropout=0.2, loss='mae'):\n",
        "    optim = Adam(lr=lr)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(CuDNNLSTM(units=128, return_sequences=True))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(CuDNNLSTM(units=128, return_sequences=True,))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(CuDNNLSTM(units=128))\n",
        "    model.add(Dense(units=N_STOCKS))\n",
        "    model.compile(optimizer=optim, loss=loss)\n",
        "    return model\n",
        "\n",
        "lstm = create_model()\n",
        "lstm.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kfRY_Om8D5J",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9HF53W8nuyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm.fit(X_train_lstm, y, epochs=1000, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFZcePZrpVCE",
        "colab_type": "text"
      },
      "source": [
        "# Create submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-PjMCNrpW_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DAYS_N = 152\n",
        "\n",
        "def create_submission(model, Xte, prices, file_name):\n",
        "    # Predictions\n",
        "    preds = model.predict(Xte).flatten()\n",
        "    assert len(preds) == DAYS_N*(N_STOCKS+1)\n",
        "\n",
        "    # Data Id labels\n",
        "    dataid = []\n",
        "    stock_names = prices.columns\n",
        "    for i in range(DAYS_N):\n",
        "        for stock in stock_names:\n",
        "            dataid.append(str(i)+'_'+str(stock))\n",
        "    \n",
        "    assert len(dataid) == DAYS_N*(N_STOCKS+1)\n",
        "    dataid = np.array(dataid)\n",
        "\n",
        "    # Combine for submission\n",
        "    df = pd.DataFrame({'Id':dataid, 'Predicted': preds})\n",
        "    df.to_csv(file_name+'.csv', index=False)\n",
        "\n",
        "    print(\"Submission: {}.csv Created\".format(file_name))\n",
        "\n",
        "create_submission(fcc_model, X_test, prices, 'sub_fcc')\n",
        "create_submission(lstm_model, X_test, prices, 'sub_lstm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9lu0Nln9s1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uJ2FWWF9s35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H248bH-F9s5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}